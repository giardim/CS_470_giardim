****************************************
APPROACHES: 
****************************************

* CNN0
	 A model with convolutional layers that go up to size 64 and a padding of 'same'. There is also a pooling layer of stride 2. This model uses the leaky RElU activation function. While training, this model also randomly flips images horizontally.

* CNN1
	 A model with convolutional layers that go up to size 128 and a padding of 'same'. There is also a pooling layer of stride 1. This model uses the RElU activation function and has 2 dropout layers with 15% probability. While training, this model also randomly flips images vertically.

****************************************
RESULTS:
****************************************
APPROACH	TRAINING_accuracy	TRAINING_f1	TESTING_accuracy	TESTING_f1
CNN0	0.8586	0.8576	0.7728	0.7710
CNN1	0.8522	0.8505	0.6240	0.6190

****************************************
MODEL ARCHITECTURES:
****************************************
* CNN0
CNN0(
  (CNN0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (3): LeakyReLU(negative_slope=0.01)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (8): LeakyReLU(negative_slope=0.01)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Flatten(start_dim=1, end_dim=-1)
    (11): Linear(in_features=4096, out_features=32, bias=True)
    (12): LeakyReLU(negative_slope=0.01)
    (13): Linear(in_features=32, out_features=10, bias=True)
  )
)

* CNN1
CNN1(
  (CNN1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (1): Dropout(p=0.05, inplace=False)
    (2): ReLU()
    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (4): ReLU()
    (5): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (7): Dropout(p=0.05, inplace=False)
    (8): ReLU()
    (9): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (10): ReLU()
    (11): MaxPool2d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)
    (12): Flatten(start_dim=1, end_dim=-1)
    (13): Linear(in_features=131072, out_features=32, bias=False)
    (14): ReLU()
    (15): Linear(in_features=32, out_features=10, bias=False)
  )
)

