****************************************
APPROACHES: 
****************************************

* CNN0
	 14 Layer CNN with Leaky ReLU as the activation function. Uses convolution layers to transform the data.

* CNN1
	 17 Layer CNN with Sigmoid as the activation function. Uses convolution layers to transform the data. Also has a dropout rate of 5%. Data is randomly flipped horizontally.

* CNN2
	 20 Layer CNN with ReLu as the activation function. Uses linear layers to transform the data. Data is randomly flipped vertically.

* CNN3
	 17 Layer CNN with ReLu as the activation function. Uses convolution to transform the data. One of the convolution layers has a stride length of 2.

****************************************
RESULTS:
****************************************
APPROACH	TRAINING_accuracy	TRAINING_f1	TESTING_accuracy	TESTING_f1
CNN0	0.4018	0.3976	0.3966	0.3923
CNN1	0.4062	0.3932	0.4057	0.3913
CNN2	0.3280	0.3074	0.3257	0.3051
CNN3	0.2345	0.1783	0.2366	0.1799

****************************************
MODEL ARCHITECTURES:
****************************************
* CNN0
CNN0(
  (CNN0): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (1): LeakyReLU(negative_slope=0.01)
    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (3): LeakyReLU(negative_slope=0.01)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (6): LeakyReLU(negative_slope=0.01)
    (7): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (8): LeakyReLU(negative_slope=0.01)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Flatten(start_dim=1, end_dim=-1)
    (11): Linear(in_features=4096, out_features=32, bias=True)
    (12): LeakyReLU(negative_slope=0.01)
    (13): Linear(in_features=32, out_features=10, bias=True)
  )
)

* CNN1
CNN1(
  (CNN1): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (1): Dropout(p=0.05, inplace=False)
    (2): Sigmoid()
    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (4): Sigmoid()
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (7): Dropout(p=0.05, inplace=False)
    (8): Sigmoid()
    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)
    (10): Sigmoid()
    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (12): Flatten(start_dim=1, end_dim=-1)
    (13): Linear(in_features=4096, out_features=32, bias=True)
    (14): Dropout(p=0.05, inplace=False)
    (15): Sigmoid()
    (16): Linear(in_features=32, out_features=10, bias=True)
  )
)

* CNN2
CNN2(
  (CNN2): Sequential(
    (0): Linear(in_features=32, out_features=3, bias=True)
    (1): ReLU()
    (2): Linear(in_features=3, out_features=64, bias=True)
    (3): ReLU()
    (4): Linear(in_features=64, out_features=64, bias=True)
    (5): ReLU()
    (6): Linear(in_features=64, out_features=64, bias=True)
    (7): ReLU()
    (8): Linear(in_features=64, out_features=64, bias=True)
    (9): ReLU()
    (10): Linear(in_features=64, out_features=64, bias=True)
    (11): ReLU()
    (12): Linear(in_features=64, out_features=64, bias=True)
    (13): ReLU()
    (14): Linear(in_features=64, out_features=64, bias=True)
    (15): ReLU()
    (16): Linear(in_features=64, out_features=64, bias=True)
    (17): ReLU()
    (18): Flatten(start_dim=1, end_dim=-1)
    (19): Linear(in_features=6144, out_features=10, bias=True)
  )
)

* CNN3
CNN3(
  (CNN3): Sequential(
    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))
    (1): ReLU()
    (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    (3): ReLU()
    (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    (5): ReLU()
    (6): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    (7): ReLU()
    (8): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))
    (9): ReLU()
    (10): Conv2d(64, 64, kernel_size=(1, 1), stride=(2, 2))
    (11): ReLU()
    (12): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)
    (13): Flatten(start_dim=1, end_dim=-1)
    (14): Linear(in_features=64, out_features=32, bias=True)
    (15): ReLU()
    (16): Linear(in_features=32, out_features=10, bias=True)
  )
)

